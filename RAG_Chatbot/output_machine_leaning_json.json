{
  "\"What is Linear Regression\"": "\"Linear regression is a statistical method used to model the relationship between a dependent variable (target) and one or more independent variables (predictors) by fitting a linear equation to observed data.\",",
  "\"What is  R-squared\"": "\"R-squared is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by the independent variables in a regression model.\",",
  "\"what is the Adjusted R-squared\"": "\"Adjusted R-squared modifies R² to account for the number of predictors in the model. It provides a more accurate measure when comparing models with different numbers of independent variables\",",
  "\"What is Multicollinearity\"": "\"Multicollinearity occurs when two or more independent variables in a regression model are highly correlated leading to unreliable estimates of regression coefficients\",",
  "\"How to Detect Multicollinearity\"": "\"Variance Inflation Factor (VIF): A measure that quantifies how much the variance of a regression coefficient is inflated due to collinearity with other predictors",
  "Formula": "VIF = 1 / (1 - R²)en.wikipedia.org+1investopedia.com+1",
  "Interpretation": "",
  "VIF = 1": "No correlation between the predictor and other variables.",
  "VIF > 1": "Indicates some correlation.",
  "VIF > 10": "High multicollinearity suggesting the need for corrective measures.",
  "Correction Methods": "",
  "\" What Are the Assumptions of Linear Regression\"": "\"Linear regression models rely on several key assumptions to produce reliable and valid results:",
  "Linearity": "The relationship between the dependent and independent variables is linear.",
  "Independence": "Observations are independent of each other.",
  "Homoscedasticity": "The variance of the residuals is constant across all levels of the independent variable(s).",
  "Normality of Residuals": "The residuals are normally distributed.investopedia.com+10statisticsbyjim.com+10geeksforgeeks.org+10",
  "No Multicollinearity": "The independent variables are not highly correlated with each other.",
  "No Autocorrelation": "The residuals are not correlated with each other especially important in time series data.\",",
  "\"Explain Homoscedasticity\"": "\"Homoscedasticity: Occurs when the variance of the residuals is constant across all levels of the independent variable(s).",
  "Example": "Predicting income based on years of education where the variability in income is consistent across all education levels.\",",
  "\"what is Heteroscedasticity": "\": \"Heteroscedasticity: Occurs when the variance of the residuals varies across levels of the independent variable(s).\",",
  "\"How to Detect Heteroscedasticity\"": "\"Residual Plots: Plotting residuals against fitted values or independent variables. A funnel shape indicates heteroscedasticity.",
  "Breusch–Pagan Test": "Statistical test that regresses squared residuals on the independent variables to detect heteroscedasticity.",
  "Goldfeld–Quandt Test": "Divides the data into two groups and compares the variances of residuals to detect heteroscedasticity.",
  "White Test": "A general test that detects heteroscedasticity and model misspecification.\",",
  "\"Define RMSE.\"": "\"The Root Mean Squared Error (RMSE) is the square root of the MSE. It provides a measure of the average magnitude of the errors in a set of predictions expressed in the same units as the target variable.\",",
  "\"What is Machine Learning\"": "\"Machine Learning is a subset of artificial intelligence that allows computers to learn from data and make predictions or decisions without being explicitly programmed.\",",
  "\"  What is Overfitting\"": "\"Overfitting happens when a model learns both the patterns and noise in the training data, performing well on training data but poorly on new (test) data.\"",
  "\" What are the types of Machine Learning\"": "\"Supervised Learning – Learns from labeled data (e.g., spam detection).",
  "\" What is Underfitting\"": "\"Underfitting occurs when a model is too simple to capture the patterns in the data, resulting in poor performance on both training and test data.\"",
  "\" What is the difference between Regression and Classification?\"": "\" Regression predicts continuous values (e.g., house price).",
  "\" What is a Confusion Matrix \"": "\" A confusion matrix is a table used to evaluate classification models by showing true positives, false positives, true negatives, and false negatives. \"",
  "\" What is Feature Engineering? \"": "\" Feature engineering involves selecting, modifying, or creating new input variables (features) to improve a model’s performance.",
  "\"  What is PCA (Principal Component Analysis)\"": "\" PCA is a dimensionality reduction technique that transforms data into fewer dimensions while retaining most of the original variability. \""
}